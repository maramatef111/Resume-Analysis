{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Installing the required packages**"
   ],
   "metadata": {
    "id": "m3T0HdgmwD5R"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install PyPDF2"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMKcmb8lGJ24",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750253911907,
     "user_tz": -180,
     "elapsed": 7671,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "6be46cd2-d943-48f0-8852-f35d854db985"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install textract\n",
    "!pip install docx2txt"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kAfoA9aVGzmU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750254054366,
     "user_tz": -180,
     "elapsed": 9180,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "f3e16727-9155-444e-bd19-b99d340f54b7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting textract\n",
      "  Downloading textract-1.6.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[33mWARNING: Ignoring version 1.6.5 of textract since it has invalid metadata:\n",
      "Requested textract from https://files.pythonhosted.org/packages/6b/3e/ac16b6bf28edf78296aea7d0cb416b49ed30282ac8c711662541015ee6f3/textract-1.6.5-py3-none-any.whl has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    extract-msg (<=0.29.*)\n",
      "                 ~~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading textract-1.6.4.tar.gz (17 kB)\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m\u00d7\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m\u2502\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m\u2570\u2500>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m\u00d7\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m\u2570\u2500>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
      "Downloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.9\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install nltk"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ayq6RiD-LabT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750254161757,
     "user_tz": -180,
     "elapsed": 4826,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "b1f87700-1844-4b36-a8a5-274db56c1dc4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3QT1l62aF-Ls"
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import docx2txt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \" \"\n",
    "    return text"
   ],
   "metadata": {
    "id": "41e_E3PUITDM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Resumes we are going to use**"
   ],
   "metadata": {
    "id": "bNpOf8Lzwlvc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "resume1=extract_text_from_pdf('MARAM ATEF SAEED.pdf')"
   ],
   "metadata": {
    "id": "DmpLK1yCH7La"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "resume2=extract_text_from_pdf('IOS1 (1).pdf')"
   ],
   "metadata": {
    "id": "Ik91Puv6zOdx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "resume3=extract_text_from_pdf('/content/Fatma.Hassan..pdf')\n"
   ],
   "metadata": {
    "id": "C9gkigIFzXL0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "resume4=extract_text_from_pdf('android-developer-1559034496.pdf')"
   ],
   "metadata": {
    "id": "Xew8_4sPzW8T"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Preprocessing Resume**"
   ],
   "metadata": {
    "id": "1qziYH9jyVcH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    return ' '.join(words)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvBdwu9fLb01",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750254234393,
     "user_tz": -180,
     "elapsed": 333,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "aaf69307-a940-47e1-b98c-b80a5cf1e92d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "clean_resume1 = preprocess(resume1)\n",
    "clean_resume2 = preprocess(resume2)\n",
    "clean_resume3 = preprocess(resume3)\n",
    "clean_resume4 = preprocess(resume4)"
   ],
   "metadata": {
    "id": "h_8b4XU6LooV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Job Description can be entered by the user**"
   ],
   "metadata": {
    "id": "aBezFQrhxKbE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Prompt for the Job description.\n",
    "jd = input(\"Enter the job description: \")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdPs5DGXIGg-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750254283322,
     "user_tz": -180,
     "elapsed": 3050,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "2ba51ed9-210e-47f6-eb06-656cf8dd1026"
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job description: We are looking for a Data Scientist with strong experience in Python, machine learning, and data visualization tools such as Pandas, NumPy, and Matplotlib.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Function to get similarity score between resume and JD with the help of cosine similarity**"
   ],
   "metadata": {
    "id": "Xyrq5Q76xOiz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_similarity(resume, jd):\n",
    "    res = ''.join([i for i in resume if not i.isdigit()])\n",
    "    res_jd=[res, jd]\n",
    "    cntv = CountVectorizer()\n",
    "    count_matrix = cntv.fit_transform(res_jd)\n",
    "    percentage = round((cosine_similarity(count_matrix)[0][1] * 100),2)\n",
    "    return percentage"
   ],
   "metadata": {
    "id": "PHajy2XYIcEO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Similarity score of  applicants**"
   ],
   "metadata": {
    "id": "sNEc5tkexY9R"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "per1=get_similarity(clean_resume1,jd)\n",
    "print(\"\\nSimilarity Scores: between resume 1 and Job Description is \",per1)\n",
    "per2=get_similarity(clean_resume2,jd)\n",
    "print(\"\\nSimilarity Scores: between resume 2 and Job Description is \",per2)\n",
    "per3 = get_similarity(clean_resume3,jd)\n",
    "print(\"\\nSimilarity Scores: between resume 3 and Job Description is \",per3)\n",
    "per4 = get_similarity(clean_resume4,jd)\n",
    "print(\"\\nSimilarity Scores: between resume 4 and Job Description is \",per4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VyUFkz6HIjks",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750254881710,
     "user_tz": -180,
     "elapsed": 47,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "d6bb88a6-b35a-4509-908d-e29f924438f1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Similarity Scores: between resume 1 and Job Description is  36.2\n",
      "\n",
      "Similarity Scores: between resume 2 and Job Description is  6.01\n",
      "\n",
      "Similarity Scores: between resume 3 and Job Description is  17.61\n",
      "\n",
      "Similarity Scores: between resume 4 and Job Description is  8.42\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#sec way\n",
    "def jaccard_distance(clean_resume1,jd):\n",
    "    intersection=len(set.intersection(*[set(clean_resume1),set(jd)]))\n",
    "    union=len(set.union(*[set(clean_resume1),set(jd)]))\n",
    "    return intersection/float(union)\n",
    "b=jaccard_distance(clean_resume1,jd)\n",
    "\n",
    "print('\\n  Jaccard  :  ', b)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omZ-_ya2IpPR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750255397081,
     "user_tz": -180,
     "elapsed": 41,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "f0831421-1375-4877-89b6-d3e9746e1d95"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "  Jaccard  :   0.7142857142857143\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Function to do SpellCheker in the resume**"
   ],
   "metadata": {
    "id": "7PgOwoPIxsmD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pyspellchecker\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rt8YEQJFKKgu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750255423581,
     "user_tz": -180,
     "elapsed": 5525,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "481cbf61-d624-446c-9085-f9622cb5541e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.11/dist-packages (0.8.3)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def spell_check(list_of_word_lists):\n",
    "    spell_mistake = False\n",
    "    # Iterate through each list of words provided\n",
    "    for word_list in list_of_word_lists:\n",
    "        # Iterate through each word in the current list\n",
    "        for word in word_list:\n",
    "            # Check if the word is alphabetic\n",
    "            if word.isalpha():\n",
    "                # Skip if the first letter is uppercase (likely a proper noun)\n",
    "                if word[0].isupper():\n",
    "                    continue # Use continue instead of exit to proceed with the rest of the words\n",
    "                else:\n",
    "                    # Check spelling for lowercase words\n",
    "                    corrected_word = spell.correction(word.lower())\n",
    "                    if word.lower() != corrected_word:\n",
    "                        print('wrong spelling: ', word, '\\nSuggestions are as follow :', corrected_word)\n",
    "                        spell_mistake = True\n",
    "    if spell_mistake is False:\n",
    "        print('No spelling mistakes, good to go..')\n"
   ],
   "metadata": {
    "id": "Wbpw3ez9KQYW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "word = clean_resume1.split(),  clean_resume3.split()"
   ],
   "metadata": {
    "id": "nM3nR8TyKg8y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spell_check(word)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wS4fwDcyKjVE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750256000383,
     "user_tz": -180,
     "elapsed": 74646,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "8f941302-82aa-4970-9e95-e16682558ffb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "wrong spelling:  maram \n",
      "Suggestions are as follow : madam\n",
      "wrong spelling:  atef \n",
      "Suggestions are as follow : ate\n",
      "wrong spelling:  saeed \n",
      "Suggestions are as follow : saved\n",
      "wrong spelling:  ngineer \n",
      "Suggestions are as follow : engineer\n",
      "wrong spelling:  maramatefsaeedgmailcom \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  maram \n",
      "Suggestions are as follow : madam\n",
      "wrong spelling:  atef \n",
      "Suggestions are as follow : ate\n",
      "wrong spelling:  maram \n",
      "Suggestions are as follow : madam\n",
      "wrong spelling:  atef \n",
      "Suggestions are as follow : ate\n",
      "wrong spelling:  nlp \n",
      "Suggestions are as follow : nap\n",
      "wrong spelling:  analytics \n",
      "Suggestions are as follow : analytic\n",
      "wrong spelling:  sql \n",
      "Suggestions are as follow : sol\n",
      "wrong spelling:  yolov \n",
      "Suggestions are as follow : color\n",
      "wrong spelling:  impactful \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  shorouk \n",
      "Suggestions are as follow : shook\n",
      "wrong spelling:  nti \n",
      "Suggestions are as follow : ni\n",
      "wrong spelling:  huawei \n",
      "Suggestions are as follow : hawed\n",
      "wrong spelling:  preprocessing \n",
      "Suggestions are as follow : reprocessing\n",
      "wrong spelling:  amit \n",
      "Suggestions are as follow : admit\n",
      "wrong spelling:  perfo \n",
      "Suggestions are as follow : person\n",
      "wrong spelling:  rmance \n",
      "Suggestions are as follow : romance\n",
      "wrong spelling:  instagram \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  tr \n",
      "Suggestions are as follow : to\n",
      "wrong spelling:  monit \n",
      "Suggestions are as follow : mont\n",
      "wrong spelling:  oring \n",
      "Suggestions are as follow : bring\n",
      "wrong spelling:  yolov \n",
      "Suggestions are as follow : color\n",
      "wrong spelling:  datasets \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  eda \n",
      "Suggestions are as follow : era\n",
      "wrong spelling:  numpy \n",
      "Suggestions are as follow : bumpy\n",
      "wrong spelling:  matplotlib \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  seaborn \n",
      "Suggestions are as follow : seaborne\n",
      "wrong spelling:  nlp \n",
      "Suggestions are as follow : nap\n",
      "wrong spelling:  scikit \n",
      "Suggestions are as follow : spirit\n",
      "wrong spelling:  pytorch \n",
      "Suggestions are as follow : torch\n",
      "wrong spelling:  tensorflow \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  sql \n",
      "Suggestions are as follow : sol\n",
      "wrong spelling:  activites \n",
      "Suggestions are as follow : activities\n",
      "wrong spelling:  edu \n",
      "Suggestions are as follow : du\n",
      "wrong spelling:  tech \n",
      "Suggestions are as follow : teach\n",
      "wrong spelling:  edu \n",
      "Suggestions are as follow : du\n",
      "wrong spelling:  nasa \n",
      "Suggestions are as follow : nasal\n",
      "wrong spelling:  apps \n",
      "Suggestions are as follow : apes\n",
      "wrong spelling:  alexandrina \n",
      "Suggestions are as follow : alexandria\n",
      "wrong spelling:  hr \n",
      "Suggestions are as follow : he\n",
      "wrong spelling:  hr \n",
      "Suggestions are as follow : he\n",
      "wrong spelling:  nasa \n",
      "Suggestions are as follow : nasal\n",
      "wrong spelling:  apps \n",
      "Suggestions are as follow : apes\n",
      "wrong spelling:  hr \n",
      "Suggestions are as follow : he\n",
      "wrong spelling:  vo \n",
      "Suggestions are as follow : to\n",
      "wrong spelling:  lunteer \n",
      "Suggestions are as follow : volunteer\n",
      "wrong spelling:  enactusel \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  shorouk \n",
      "Suggestions are as follow : shook\n",
      "wrong spelling:  fatma \n",
      "Suggestions are as follow : fatwa\n",
      "wrong spelling:  hassan \n",
      "Suggestions are as follow : asian\n",
      "wrong spelling:  fatmahassanmhmdgmailcom \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  wwwlinkedincominfatmahassanaa \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  systemlevel \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  realworld \n",
      "Suggestions are as follow : dreamworld\n",
      "wrong spelling:  problemsolving \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  bsc \n",
      "Suggestions are as follow : bic\n",
      "wrong spelling:  semestersep \n",
      "Suggestions are as follow : semesters\n",
      "wrong spelling:  gpa \n",
      "Suggestions are as follow : gap\n",
      "wrong spelling:  nti \n",
      "Suggestions are as follow : ni\n",
      "wrong spelling:  pcap \n",
      "Suggestions are as follow : cap\n",
      "wrong spelling:  openedg \n",
      "Suggestions are as follow : opened\n",
      "wrong spelling:  oop \n",
      "Suggestions are as follow : top\n",
      "wrong spelling:  pythonartificial \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  nti \n",
      "Suggestions are as follow : ni\n",
      "wrong spelling:  huawei \n",
      "Suggestions are as follow : hawed\n",
      "wrong spelling:  aprpresent \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  huawei \n",
      "Suggestions are as follow : hawed\n",
      "wrong spelling:  selflearning \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  playlist \n",
      "Suggestions are as follow : playlet\n",
      "wrong spelling:  ibrahim \n",
      "Suggestions are as follow : abraham\n",
      "wrong spelling:  svm \n",
      "Suggestions are as follow : sum\n",
      "wrong spelling:  knn \n",
      "Suggestions are as follow : inn\n",
      "wrong spelling:  adaboost \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  xgboost \n",
      "Suggestions are as follow : boost\n",
      "wrong spelling:  kmeans \n",
      "Suggestions are as follow : means\n",
      "wrong spelling:  dbscan \n",
      "Suggestions are as follow : scan\n",
      "wrong spelling:  fscore \n",
      "Suggestions are as follow : score\n",
      "wrong spelling:  vx \n",
      "Suggestions are as follow : ex\n",
      "wrong spelling:  espcam \n",
      "Suggestions are as follow : scam\n",
      "wrong spelling:  hsv \n",
      "Suggestions are as follow : is\n",
      "wrong spelling:  redgreen \n",
      "Suggestions are as follow : rescreen\n",
      "wrong spelling:  esp \n",
      "Suggestions are as follow : es\n",
      "wrong spelling:  hsv \n",
      "Suggestions are as follow : is\n",
      "wrong spelling:  thresholding \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  opencv \n",
      "Suggestions are as follow : open\n",
      "wrong spelling:  dlib \n",
      "Suggestions are as follow : glib\n",
      "wrong spelling:  opencv \n",
      "Suggestions are as follow : open\n",
      "wrong spelling:  opencv \n",
      "Suggestions are as follow : open\n",
      "wrong spelling:  dlib \n",
      "Suggestions are as follow : glib\n",
      "wrong spelling:  svm \n",
      "Suggestions are as follow : sum\n",
      "wrong spelling:  svmbased \n",
      "Suggestions are as follow : sambaed\n",
      "wrong spelling:  opencv \n",
      "Suggestions are as follow : open\n",
      "wrong spelling:  sklearn \n",
      "Suggestions are as follow : learn\n",
      "wrong spelling:  vl \n",
      "Suggestions are as follow : al\n",
      "wrong spelling:  hsv \n",
      "Suggestions are as follow : is\n",
      "wrong spelling:  thresholding \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  hsv \n",
      "Suggestions are as follow : is\n",
      "wrong spelling:  thresholding \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  numpay \n",
      "Suggestions are as follow : bumpy\n",
      "wrong spelling:  opencv \n",
      "Suggestions are as follow : open\n",
      "wrong spelling:  texttospeech \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  espcam \n",
      "Suggestions are as follow : scam\n",
      "wrong spelling:  tts \n",
      "Suggestions are as follow : its\n",
      "wrong spelling:  espcam \n",
      "Suggestions are as follow : scam\n",
      "wrong spelling:  opencv \n",
      "Suggestions are as follow : open\n",
      "wrong spelling:  pyttsx \n",
      "Suggestions are as follow : putts\n",
      "wrong spelling:  uwr \n",
      "Suggestions are as follow : ur\n",
      "wrong spelling:  orce \n",
      "Suggestions are as follow : once\n",
      "wrong spelling:  grc \n",
      "Suggestions are as follow : arc\n",
      "wrong spelling:  competitionjuly \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  seaperch \n",
      "Suggestions are as follow : search\n",
      "wrong spelling:  rov \n",
      "Suggestions are as follow : rob\n",
      "wrong spelling:  gui \n",
      "Suggestions are as follow : guy\n",
      "wrong spelling:  rov \n",
      "Suggestions are as follow : rob\n",
      "wrong spelling:  sep \n",
      "Suggestions are as follow : see\n",
      "wrong spelling:  gui \n",
      "Suggestions are as follow : guy\n",
      "wrong spelling:  rov \n",
      "Suggestions are as follow : rob\n",
      "wrong spelling:  sep \n",
      "Suggestions are as follow : see\n",
      "wrong spelling:  seaperch \n",
      "Suggestions are as follow : search\n",
      "wrong spelling:  robosoccer \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  rov \n",
      "Suggestions are as follow : rob\n",
      "wrong spelling:  auv \n",
      "Suggestions are as follow : au\n",
      "wrong spelling:  rov \n",
      "Suggestions are as follow : rob\n",
      "wrong spelling:  manoeuvrable \n",
      "Suggestions are as follow : maneuverable\n",
      "wrong spelling:  rov \n",
      "Suggestions are as follow : rob\n",
      "wrong spelling:  rov \n",
      "Suggestions are as follow : rob\n",
      "wrong spelling:  leadersylf \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  sep \n",
      "Suggestions are as follow : see\n",
      "wrong spelling:  iot \n",
      "Suggestions are as follow : it\n",
      "wrong spelling:  arduino \n",
      "Suggestions are as follow : arguing\n",
      "wrong spelling:  espcam \n",
      "Suggestions are as follow : scam\n",
      "wrong spelling:  arduino \n",
      "Suggestions are as follow : arguing\n",
      "wrong spelling:  opencv \n",
      "Suggestions are as follow : open\n",
      "wrong spelling:  dlib \n",
      "Suggestions are as follow : glib\n",
      "wrong spelling:  matplotlib \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  scikitlearn \n",
      "Suggestions are as follow : None\n",
      "wrong spelling:  arduino \n",
      "Suggestions are as follow : arguing\n",
      "wrong spelling:  ide \n",
      "Suggestions are as follow : idea\n",
      "wrong spelling:  colab \n",
      "Suggestions are as follow : colas\n",
      "wrong spelling:  managementskills \n",
      "Suggestions are as follow : None\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_list = [clean_resume1, jd]\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(text_list)\n",
    "count_matrix"
   ],
   "metadata": {
    "id": "Oc-7WGyLM4r6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750256004600,
     "user_tz": -180,
     "elapsed": 6,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "19a280ab-e57b-4f01-eeaf-60414544efa9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 221 stored elements and shape (2, 210)>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "matchPercentage = cosine_similarity(count_matrix)\n",
    "print(matchPercentage)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mJ3MFOCfl62",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750256019211,
     "user_tz": -180,
     "elapsed": 9,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "5d43e78e-04d4-4bab-f0d7-65ec9bc20986"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.         0.36203005]\n",
      " [0.36203005 1.        ]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\n",
    "matchPercentage = round(matchPercentage, 2)\n",
    "print(\"Your resume matches about \"+ str(matchPercentage)+ \"% of the job description.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsmRiu4Rfpk7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750256041962,
     "user_tz": -180,
     "elapsed": 19,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "3942acd9-01de-4de5-af6b-da2e98b734da"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Your resume matches about 36.2% of the job description.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Summarizing Resume**"
   ],
   "metadata": {
    "id": "UpY2iMwAx42r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install bert-extractive-summarizer"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPapd2Hch-a3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750256063124,
     "user_tz": -180,
     "elapsed": 6201,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "17bcc026-55e2-4121-e881-b3ab227aa6dd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting bert-extractive-summarizer\n",
      "  Downloading bert_extractive_summarizer-0.10.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from bert-extractive-summarizer) (4.52.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from bert-extractive-summarizer) (1.6.1)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from bert-extractive-summarizer) (3.8.7)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->bert-extractive-summarizer) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->bert-extractive-summarizer) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (2.11.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (75.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->bert-extractive-summarizer) (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->bert-extractive-summarizer) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->bert-extractive-summarizer) (0.33.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->bert-extractive-summarizer) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->bert-extractive-summarizer) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->bert-extractive-summarizer) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->bert-extractive-summarizer) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->bert-extractive-summarizer) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->bert-extractive-summarizer) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->bert-extractive-summarizer) (1.1.3)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->bert-extractive-summarizer) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->bert-extractive-summarizer) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy->bert-extractive-summarizer) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (0.1.2)\n",
      "Downloading bert_extractive_summarizer-0.10.1-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: bert-extractive-summarizer\n",
      "Successfully installed bert-extractive-summarizer-0.10.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from summarizer import Summarizer\n",
    "model = Summarizer()\n",
    "summary = model(resume1)\n",
    "print(summary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3hIG53C04zR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750256453582,
     "user_tz": -180,
     "elapsed": 3469,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "fa54f2c1-0775-478d-e2bf-bcc48db29152"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Maram Atef Saeed    \n",
      " AI E ngineer | Data Scientist | Data Analyst  \n",
      "  maramatefsaeed@gmail.com      01003828340     Maram Atef        Maram Atef         Cairo,  Egypt   \n",
      "SUMMARY  \n",
      "AI Engineer, Data Scientist, and Data Analyst with hands -on experience in machine learning, deep learning, computer vision, NLP, \n",
      "and data analytics. Sales Analysis  , Cleaned and merged sales datasets using Pandas, performed EDA and visualizations to uncover trends,  top \n",
      "products, peak hours, and advertising opportunities.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Accuracy Summarizing Resume**"
   ],
   "metadata": {
    "id": "_0_eV5y4x-R1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install bert-score"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iSZzQUKcj2M-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750256668245,
     "user_tz": -180,
     "elapsed": 175849,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "7fa244f9-b043-4beb-e576-8b465984f503"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.52.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert-score)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert-score)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert-score)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert-score)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert-score)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert-score)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.33.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.4.26)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert-score) (1.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m930.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m590.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "nvidia"
        ]
       },
       "id": "80399a3a65b14fd8b5dddfd6aba846c1"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from bert_score import score\n",
    "\n",
    "\n",
    "predicted_summaries = [summary]\n",
    "reference_summaries = [resume1]\n",
    "\n",
    "# Calculate BERTScore\n",
    "P, R, F1 = score(predicted_summaries, reference_summaries, lang=\"en\", model_type=\"bert-base-uncased\")\n",
    "\n",
    "print(f\"Precision: {P.mean().item():.4f}\")\n",
    "print(f\"Recall: {R.mean().item():.4f}\")\n",
    "print(f\"F1 Score: {F1.mean().item():.4f}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229,
     "referenced_widgets": [
      "8fdd13b4c23a44d0b27590c1a285fd3c",
      "b1e8f398870e4e36920280130752637a",
      "378342a191364811b631dd3f2f7e7df8",
      "7c59d7eb0e3c48afac1c872ace255729",
      "84f0146ad9e44868a71008e1a5ffa9bd",
      "280276847e934517a93213bc2c2f3c5a",
      "59e052441f7a418abc23c4bc773b49e5",
      "1e734fe940e24a758a993f222c78a011",
      "f036925e240c433fa9df0cc03983b410",
      "47cecad476304741a3ae098c151e7359",
      "997c8755d3a84b639119dc2d5623cfc0",
      "2aa4396b6a4b47bbaade45f193c916a9",
      "0624671665104370b1257a713e8972c0",
      "be446abc3591478392ebaa38529511ae",
      "bb659fa881f54890b0c67844ee6888b2",
      "059b3b424716404b9e81110f7ac08350",
      "5ad50ce56ee242d0b77dfc0780ff568d",
      "459bf4f32746408684c18de757eceac2",
      "da1d43299f29421194137bca2eea27b1",
      "227e978e139744f1bc6b09ffd0030162",
      "0d684fa191b24ff99f13b68d642587f8",
      "30435df1726c4bf892ab1ad7840a2b4f",
      "90d574769a6540b3a6dd42a94d4fdb36",
      "74e6b851e3a443faa2df2e8a7fec6c05",
      "93770dc9a15845139808f0c3916c1553",
      "385f575e703d4d2587df0a0b5a5e7047",
      "86ee9328f2de4b3589526a326371eecc",
      "5729c8ad5f7548c1952f62d5ec0e487d",
      "c5fdec4b0c844f8d80aeb2d195c18618",
      "c07c6802d0c643e0a5ee36133e70eabe",
      "c96669efb8364f4fb0c84030ca667a82",
      "66f91d5dda9d4b89917bee8a6ff17402",
      "1d3a7ab670ef4da5a18bb4d1c44e7e05",
      "2e283ca271904183bcd6ad4dbf383609",
      "e57c77bdb62f4dee95fbb20a874a7290",
      "ead801213bde499c8bd1753204c2aee9",
      "9ed6acfacb0e44799be33f142a02a453",
      "e8fccc36d42c46d9926613780dc84e32",
      "4b7042301d5d48b1bda3423ff7754b44",
      "4f8e118c76874f2789cbc942a1893e2a",
      "16efaad4d4994332a473dd312f00d8ae",
      "fae02c66eea44e148ab1552deedf802f",
      "119a686695ed445592318c4001e883fd",
      "534490c5a19c41c5b4fc96cf9eae309c",
      "b209351e041f46d8b878103faba3d393",
      "9716a00550d8435d82b7ebcc2e89bb40",
      "36f1c11d5149478ab6ef42a6d0c4865c",
      "35bfb62708a74944a4959e29c3ca4374",
      "2693aede86b941619382fa25cd68f6b1",
      "87494ab1a1364c9884bf3c1faac46622",
      "0df75bfb4cb84775901edf1611d9d3c2",
      "4453b35579c04afdb6f8299138d3aef0",
      "983fc49e47634577a5c0e836a91220f4",
      "5730e10bc1fc4f9f8c74757c4799d9ba",
      "b5e0701212c747d99b69668b505e0ba3"
     ]
    },
    "id": "-Jawnsa-1A2H",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750256705376,
     "user_tz": -180,
     "elapsed": 37093,
     "user": {
      "displayName": "Fatma Hassan",
      "userId": "11769089081855247124"
     }
    },
    "outputId": "6823d417-3efa-401c-9412-ac7d505711bb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fdd13b4c23a44d0b27590c1a285fd3c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2aa4396b6a4b47bbaade45f193c916a9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90d574769a6540b3a6dd42a94d4fdb36"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e283ca271904183bcd6ad4dbf383609"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b209351e041f46d8b878103faba3d393"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: 0.8821\n",
      "Recall: 0.5874\n",
      "F1 Score: 0.7052\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "Ln77_WVKDyCK"
   }
  }
 ]
}